{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3avdI4gdzxI",
        "outputId": "60753dad-0bb8-4bff-e67d-b62fd107b51f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install botorch\n",
        "\n",
        "\n",
        "import json\n",
        "\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import botorch\n",
        "from botorch.models import SingleTaskGP\n",
        "from botorch.utils import standardize\n",
        "from botorch.acquisition import UpperConfidenceBound\n",
        "from botorch.acquisition import ExpectedImprovement\n",
        "from botorch.sampling import SobolQMCNormalSampler\n",
        "from botorch.acquisition import qNoisyExpectedImprovement\n",
        "from botorch.optim import optimize_acqf\n",
        "\n",
        "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
        "from botorch import fit_gpytorch_model\n",
        "from botorch.acquisition.monte_carlo import qExpectedImprovement\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qMW6Oj2uzfa",
        "outputId": "63cef2a1-ee70-4c1d-de6c-74cc16d67e68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting botorch\n",
            "  Downloading botorch-0.8.5-py3-none-any.whl (530 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/530.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/530.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m530.3/530.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from botorch) (1.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from botorch) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.12 in /usr/local/lib/python3.10/dist-packages (from botorch) (2.0.1+cu118)\n",
            "Collecting pyro-ppl>=1.8.4 (from botorch)\n",
            "  Downloading pyro_ppl-1.8.5-py3-none-any.whl (732 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m732.5/732.5 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gpytorch==1.10 (from botorch)\n",
            "  Downloading gpytorch-1.10-py3-none-any.whl (255 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.2/255.2 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting linear-operator==0.4.0 (from botorch)\n",
            "  Downloading linear_operator-0.4.0-py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.7/156.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from gpytorch==1.10->botorch) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl>=1.8.4->botorch) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl>=1.8.4->botorch) (3.3.0)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl>=1.8.4->botorch)\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl>=1.8.4->botorch) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->botorch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->botorch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->botorch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->botorch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->botorch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->botorch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.12->botorch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.12->botorch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12->botorch) (2.1.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch==1.10->botorch) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch==1.10->botorch) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12->botorch) (1.3.0)\n",
            "Installing collected packages: pyro-api, linear-operator, pyro-ppl, gpytorch, botorch\n",
            "Successfully installed botorch-0.8.5 gpytorch-1.10 linear-operator-0.4.0 pyro-api-0.1.2 pyro-ppl-1.8.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVeL1cLNbmQm",
        "outputId": "1a3d3adb-4da5-41a6-ce13-e581d712e628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'version_experiment': 2003, 'epoch': 1, 'test_miou_acc_ibg': 0.0, 'optimizer': 0, 'architecture_used': 0, 'network': 0, 'batch_size': 1, 'learning_rate': 0.8101972717544853, 'momentum': 0, 'weight_decay': 0.5128159537541757, 'loss_function': 0}\n",
            "{'version_experiment': 2003, 'epoch': 2, 'test_miou_acc_ibg': 0.044774421490728855, 'optimizer': 0, 'architecture_used': 0, 'network': 0, 'batch_size': 1, 'learning_rate': 0.8101972717544853, 'momentum': 0, 'weight_decay': 0.5128159537541757, 'loss_function': 0}\n",
            "{'version_experiment': 2003, 'epoch': 3, 'test_miou_acc_ibg': 0.0, 'optimizer': 0, 'architecture_used': 0, 'network': 0, 'batch_size': 1, 'learning_rate': 0.8101972717544853, 'momentum': 0, 'weight_decay': 0.5128159537541757, 'loss_function': 0}\n",
            "{'version_experiment': 2003, 'epoch': 4, 'test_miou_acc_ibg': 0.0, 'optimizer': 0, 'architecture_used': 0, 'network': 0, 'batch_size': 1, 'learning_rate': 0.8101972717544853, 'momentum': 0, 'weight_decay': 0.5128159537541757, 'loss_function': 0}\n",
            "{'version_experiment': 2003, 'epoch': 5, 'test_miou_acc_ibg': 0.044774421490728855, 'optimizer': 0, 'architecture_used': 0, 'network': 0, 'batch_size': 1, 'learning_rate': 0.8101972717544853, 'momentum': 0, 'weight_decay': 0.5128159537541757, 'loss_function': 0}\n",
            "{'version_experiment': 2003, 'epoch': 6, 'test_miou_acc_ibg': 0.0, 'optimizer': 0, 'architecture_used': 0, 'network': 0, 'batch_size': 1, 'learning_rate': 0.8101972717544853, 'momentum': 0, 'weight_decay': 0.5128159537541757, 'loss_function': 0}\n",
            "{'version_experiment': 2003, 'epoch': 7, 'test_miou_acc_ibg': 0.0, 'optimizer': 0, 'architecture_used': 0, 'network': 0, 'batch_size': 1, 'learning_rate': 0.8101972717544853, 'momentum': 0, 'weight_decay': 0.5128159537541757, 'loss_function': 0}\n",
            "{'version_experiment': 2003, 'epoch': 8, 'test_miou_acc_ibg': 0.0, 'optimizer': 0, 'architecture_used': 0, 'network': 0, 'batch_size': 1, 'learning_rate': 0.8101972717544853, 'momentum': 0, 'weight_decay': 0.5128159537541757, 'loss_function': 0}\n",
            "{'version_experiment': 2003, 'epoch': 9, 'test_miou_acc_ibg': 0.044774421490728855, 'optimizer': 0, 'architecture_used': 0, 'network': 0, 'batch_size': 1, 'learning_rate': 0.8101972717544853, 'momentum': 0, 'weight_decay': 0.5128159537541757, 'loss_function': 0}\n",
            "[(1, 30), (0, 1), (0, 0), (0, 0), (0, 2), (0.0001, 0.9), (0, 0), (0.0001, 0.9), (0, 0)]\n",
            "best observed value for y_ibg 0.04477442055940628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-288305f7ba53>:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X = torch.tensor(X, dtype=torch.double)\n",
            "<ipython-input-21-288305f7ba53>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_ibg = torch.tensor(y_ibg, dtype=torch.double)\n",
            "/usr/local/lib/python3.10/dist-packages/botorch/models/utils/assorted.py:173: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
            "  warnings.warn(msg, InputDataWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/botorch/models/utils/assorted.py:201: InputDataWarning: Input data is not standardized. Please consider scaling the input to zero mean and unit variance.\n",
            "  warnings.warn(msg, InputDataWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[8.7924e+00, 7.1194e-20, 0.0000e+00, 0.0000e+00, 1.0000e+00, 8.1019e-01,\n",
            "         0.0000e+00, 5.1282e-01, 0.0000e+00]], dtype=torch.float64)\n",
            "[8.792405449853957, 7.119391844327822e-20, 0.0, 0.0, 1.0000025635008276, 0.8101881214852589, 0.0, 0.5128153937755331, 0.0]\n",
            "{'epoch': 9, 'optimizer': 'SGD', 'architecture_used': 'DeepLabV3', 'network': 'resnet18', 'batch_size': 8, 'learning_rate': 0.8101881214852589, 'momentum': 0.9, 'weight_decay': 0.5128153937755331, 'loss_function': 'CrossEntropyLoss'}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "data_path_bayesian_opti = Path(\"/content/gdrive/MyDrive/Thesis_deeplearning_models/\")\n",
        "\n",
        "filename_training_bayesian_opti = data_path_bayesian_opti / \"training_data_opti.txt\"\n",
        "\n",
        "# Read the contents of the file\n",
        "with open(filename_training_bayesian_opti, 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "    # Parse the content as JSON\n",
        "    training_data_bayesian_opti = json.loads(content)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "original_bound_values = {\n",
        "    'optimizer':['SGD', 'Adam'],\n",
        "    'architecture_used': ['DeepLabV3'],\n",
        "    'network': ['resnet18'],\n",
        "    'batch_size': [4,8,16],\n",
        "    'momentum': [0.9],\n",
        "    'loss_function': ['CrossEntropyLoss']\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "transformed_bound_values = {}\n",
        "\n",
        "training_data_bayesian_opti_modified = training_data_bayesian_opti.copy()\n",
        "\n",
        "valid_rows = []\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Transform the original values into values that can be processed by the model\n",
        "\"\"\"\n",
        "for row_training_data_modified in training_data_bayesian_opti_modified:\n",
        "    ok = True\n",
        "    for key in original_bound_values:\n",
        "        features_table = original_bound_values[key]\n",
        "        # Create a dictionary to map batch sizes to integer values\n",
        "        size_mapping = {size: idx for idx, size in enumerate(features_table)}\n",
        "\n",
        "        # Perform integer encoding on the dataset\n",
        "        encoded_data = [size_mapping[features] for features in features_table]\n",
        "        tuple_encoded_data = (encoded_data[0], encoded_data[-1])\n",
        "        # Updates the values to numerical ones\n",
        "        transformed_bound_values[key] = tuple_encoded_data\n",
        "\n",
        "        if row_training_data_modified[key] in size_mapping:\n",
        "            row_training_data_modified[key] = size_mapping[row_training_data_modified[key]]\n",
        "        else:\n",
        "            ok = False\n",
        "\n",
        "\n",
        "    if(ok == True):\n",
        "      valid_rows.append(row_training_data_modified)\n",
        "\n",
        "\n",
        "training_data_bayesian_opti_modified = valid_rows\n",
        "\n",
        "\n",
        "\n",
        "countb = 0\n",
        "for features_row_modified in training_data_bayesian_opti_modified:\n",
        "    countb+=1\n",
        "print(\"Number of valid rows : \" + str(countb))\n",
        "\n",
        "\n",
        "# Define the bounds for each hyperparameter\n",
        "bounds = [\n",
        "    (1,30),                                             # What is the best epoch between 1 and 30? We ran experiments between 10 and 30.\n",
        "    transformed_bound_values['optimizer'],              # optimizer: 0 for 'SGD', 1 for 'Adam'\n",
        "    transformed_bound_values['architecture_used'],      # architecture_used: 0 for 'DeepLabV3'\n",
        "    transformed_bound_values['network'],                # network: 0 for 'resnet18'\n",
        "    transformed_bound_values['batch_size'],             # batch_size: 0 for 4, 1 for 8, 2 for 16\n",
        "    (0.0001, 0.9),                                      # learning_rate\n",
        "    transformed_bound_values['momentum'],               # momentum: 0.9 (fixed value)\n",
        "    (0.0001, 0.9),                                      # weight_decay\n",
        "    transformed_bound_values['loss_function'],          # loss_function: 0 for 'CrossEntropyLoss', 1 for 'Focal Loss', 2 'Dice Loss'\n",
        "]\n",
        "\n",
        "print(bounds)\n",
        "\n",
        "\n",
        "X = torch.tensor([[features_row['epoch'], features_row['optimizer'], features_row['architecture_used'],\n",
        "                   features_row['network'], features_row['batch_size'], features_row['learning_rate'],\n",
        "                                      features_row['momentum'], features_row['weight_decay'], features_row['loss_function']]\n",
        "                                                        for features_row in training_data_bayesian_opti_modified], dtype=torch.double)\n",
        "\n",
        "\n",
        "\n",
        "y_ibg = torch.tensor([[features_row['test_miou_acc_ibg']] for features_row in training_data_bayesian_opti_modified])\n",
        "\n",
        "\n",
        "\n",
        "X = torch.tensor(X, dtype=torch.double)\n",
        "y_ibg = torch.tensor(y_ibg, dtype=torch.double)\n",
        "\n",
        "best_observed_y_ibg = y_ibg.max().item()\n",
        "print(\"best observed value for y_ibg \" + str(best_observed_y_ibg))\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "bounds = np.array(bounds)\n",
        "# Reshape the bounds to a 2 x 9 tensor\n",
        "bounds = bounds.T\n",
        "# Convert the bounds NumPy array to a PyTorch tensor\n",
        "bounds = torch.tensor(bounds)\n",
        "\n",
        "# SingleTaskGP model\n",
        "model_ibg = SingleTaskGP(X, y_ibg)\n",
        "\n",
        "# Define the acquisition function to maximize (e.g., Upper Confidence Bound)\n",
        "#acq_func = UpperConfidenceBound(model_ibg, beta=0.1)\n",
        "\n",
        "\n",
        "mll = ExactMarginalLogLikelihood(model_ibg.likelihood,model_ibg)\n",
        "fit_gpytorch_model(mll)\n",
        "\n",
        "acq_func = qExpectedImprovement(model_ibg, best_f=best_observed_y_ibg)\n",
        "\n",
        "\n",
        "# Optimize the hyperparameters based on the defined acquisition function\n",
        "best_hyperparameters_ibg, _ = optimize_acqf(\n",
        "    acq_function=acq_func,\n",
        "    bounds=bounds,\n",
        "    q=1,\n",
        "    num_restarts=100,\n",
        "    raw_samples=200,\n",
        ")\n",
        "\n",
        "\n",
        "print(best_hyperparameters_ibg)\n",
        "\n",
        "# Change the tensor to a list\n",
        "best_operational_hyperparameters = best_hyperparameters_ibg.tolist()[0]\n",
        "\n",
        "print(best_operational_hyperparameters)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Reverse mapping function, takes the numerical value as well as the hyperparameter concerned in input,\n",
        "and returns the original value\n",
        "\"\"\"\n",
        "def reverse_mapping(hyperparameter, value_to_reverse):\n",
        "    features_table = original_bound_values[hyperparameter]\n",
        "    # Create a dictionary to map batch sizes to integer values\n",
        "    size_mapping = {size: idx for idx, size in enumerate(features_table)}\n",
        "\n",
        "    # Reverse the key-value pairs in size_mapping\n",
        "    reversed_size_mapping = {idx: size for size, idx in size_mapping.items()}\n",
        "\n",
        "    value_to_reverse = round(value_to_reverse)\n",
        "    return reversed_size_mapping[value_to_reverse]\n",
        "\n",
        "\n",
        "best_operational_hyperparameters = {\n",
        "    'epoch': round(best_operational_hyperparameters[0]),\n",
        "    'optimizer': reverse_mapping(\"optimizer\",best_operational_hyperparameters[1]),\n",
        "    'architecture_used': reverse_mapping(\"architecture_used\",best_operational_hyperparameters[2]),\n",
        "    'network': reverse_mapping(\"network\",best_operational_hyperparameters[3]),\n",
        "    'batch_size': reverse_mapping(\"batch_size\",best_operational_hyperparameters[4]),\n",
        "    'learning_rate': best_operational_hyperparameters[5],\n",
        "    'momentum': reverse_mapping(\"momentum\",best_operational_hyperparameters[6]),\n",
        "    'weight_decay': best_operational_hyperparameters[7],\n",
        "    'loss_function': reverse_mapping(\"loss_function\",best_operational_hyperparameters[8])\n",
        "\n",
        "}\n",
        "\n",
        "print(best_operational_hyperparameters)\n",
        "\n",
        "\n",
        "del(X)\n",
        "del(y_ibg)\n",
        "del(model_ibg)\n",
        "del(acq_func)\n",
        "del(best_hyperparameters_ibg)\n",
        "del(best_operational_hyperparameters)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qMCkB6vMco1z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}